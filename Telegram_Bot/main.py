from aiogram import Bot, Dispatcher, executor, types
import os
import tempfile
import torchaudio
import requests
import torch
import opuspy
import numpy as np
import subprocess



bot = Bot(token='6294998264:AAGGTSpHfFGabeZGafEB8PxmEMi2uC4t7kU')
dp = Dispatcher(bot)

chars = {"mage":"–û–ª–∏–º–ø–∏—è –∏–∑ –•–æ–≥–≤–∞—Ä—Ç—Å–∞","jedi":"–ô–æ–¥—Ä–∏–∫ –≤–Ω—É–∫ –ô–æ–¥—ã","capybara":"üòé–ö–∞–ø–∏–±–∞—Ä–∞üòé"}

personage_voice = {"–û–ª–∏–º–ø–∏—è –∏–∑ –•–æ–≥–≤–∞—Ä—Ç—Å–∞": "olimpia", "–ô–æ–¥—Ä–∏–∫ –≤–Ω—É–∫ –ô–æ–¥—ã": "yodrick", "üòé–ö–∞–ø–∏–±–∞—Ä–∞üòé": "capybara"}
char_info = {
    'mage': '–ü—Ä–∏–≤–µ—Ç! –Ø —É—á—É—Å—å –≤ –•–æ–≥–≤–∞—Ä—Ç—Å–µ, –æ—á–µ–Ω—å –ª—é–±–ª—é —Ä–∞–∑–≥–æ–≤–æ—Ä—ã –æ–± —É—á–µ–±–µ, —Å–ø–æ—Ä—Ç–µ –∏ –º–µ—á—Ç–∞—Ö –æ –±—É–¥—É—â–µ–º! –ê —Ç—ã —Å–æ–±–∏—Ä–∞–µ—à—å –∫–∞—Ä—Ç–æ—á–∫–∏ –∏–∑-–ø–æ–¥ —à–æ–∫–ª–∞–¥–Ω—ã—Ö –ª—è–≥—É—à–µ–∫?',
    'jedi': '–î–∂–µ–¥–∞–π —è –≤–µ–ª–∏–∫–∏–π, –ô–æ–¥—Ä–∏–∫. –ú—É–¥—Ä–æ—Å—Ç—å –≤–µ–ª–∏–∫—É—é —Ç–µ–±–µ —Ä–∞—Å—Å–∫–∞–∂—É. –ó–Ω–∞—é –≤—Å–µ, –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –±—ã–ª–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ª–µ—Ç —á—Ç–æ. –†–∞—Å—Å–∫–∞–∂—É —Ç–µ–±–µ –≤–µ–ª–∏—á–∏–µ –¥–∂–µ–¥–∞–µ–≤ –≤—Å—ë, —Å–∏—Ç—Ö–æ–≤ –ø–æ–¥–ª–æ—Å—Ç—å –≤—Å—é.',
    'capybara': '–§—ã—Ä —Ñ—ã—Ä-—Ñ—ã—Ä —Ñ—ã—Ä-—Ñ—ã—Ä —Ñ—ã—Ä-—Ñ—ã—Ä —Ñ—ã—Ä, —Ñ—ã—Ä.(–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π, –º–æ–π –º–æ–ª–æ–¥–æ–π –ø—É—Ç–Ω–∏–∫. –Ø –æ—Ç–∫—Ä–æ—é —Ç–µ–±–µ –≤—Å–µ —Ç–∞–π–Ω—ã –ø—Ä–æ—à–ª–æ–≥–æ, –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ, –±—É–¥—É—â–µ–≥–æ. –ù–µ –∑–∞–±—ã–≤–∞–π –æ –¥–æ–±—Ä–æ—Ç–µ, –¥—Ä—É–≥ –º–æ–π!)'
}

@dp.message_handler(commands=['start','change_person','cp','cc','change_char','change_character'])
async def char_change(message: types.Message):
    keyboard = types.InlineKeyboardMarkup()
    keyboard.add(types.InlineKeyboardButton(text="–û–ª–∏–º–ø–∏—è –∏–∑ –•–æ–≥–≤–∞—Ä—Ç—Å–∞", callback_data="char_mage"))
    keyboard.add(types.InlineKeyboardButton(text="–ô–æ–¥—Ä–∏–∫ –≤–Ω—É–∫ –ô–æ–¥—ã", callback_data="char_jedi"))
    keyboard.add(types.InlineKeyboardButton(text="üòé–ö–∞–ø–∏–±–∞—Ä–∞üòé", callback_data="char_capybara"))
    await message.answer('–í—ã–±–µ—Ä–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞, —Å –∫–æ—Ç–æ—Ä—ã–º —Ç—ã —Ö–æ—á–µ—à—å –ø–æ–æ–±—â–∞—Ç—å—Å—è', reply_markup=keyboard)

@dp.message_handler(commands=['help'])
async def help(message: types.Message):
    keyboard = types.InlineKeyboardMarkup()
    keyboard.add(types.InlineKeyboardButton(text="–ö–Ω–æ–ø–∫–∞ –ø–æ–º–æ—â–∏ 1", callback_data="help_1"))
    keyboard.add(types.InlineKeyboardButton(text="–ö–Ω–æ–ø–∫–∞ –ø–æ–º–æ—â–∏ 2", callback_data="help_2"))
    await message.answer('–¢—É—Ç –±—É–¥–µ—Ç –ø–æ–º–æ—â—å.', reply_markup=keyboard)

@dp.message_handler(content_types=[types.ContentType.VOICE])
async def voice_message_handler(message: types.Message):
    with tempfile.NamedTemporaryFile(suffix=".wav") as temp_file:
        file_id = message.voice.file_id
        file = await bot.get_file(file_id)
        file_path = file.file_path
        print(file_path)
        print(temp_file.name)
        await bot.download_file(file_path, temp_file.name)
        audio, s_r = torchaudio.load(temp_file)
    request_disp = {"user_id": message.chat.id, "audio": audio.tolist(), "sample_rate": s_r}
    await message.answer_chat_action(types.ChatActions.RECORD_AUDIO)
    tts_answer = requests.post("http://127.0.0.1:5001/query", json=request_disp)
    with tempfile.NamedTemporaryFile(suffix=".wav") as temp_file:
        voice = torch.tensor(tts_answer.json()["audio"]).unsqueeze(0)
        torchaudio.save(temp_file.name, voice, 48000)
        result_file = temp_file.name.replace('wav', 'ogg')
        convert_to_voice_cmd = f"ffmpeg -i {temp_file.name} -c:a libopus {result_file}"
        subprocess.run(f"{convert_to_voice_cmd}", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        await message.answer_voice(voice=types.InputFile(result_file, "r"))
        await message.answer(tts_answer.json()["text_answer"])
        os.remove(result_file)

@dp.callback_query_handler(text_startswith="char")
async def char_changed(call: types.CallbackQuery):
    char_id = call.data.split("_")[1]
    character = chars[char_id]
    request_disp = {"user_id": call.message.chat.id, "character": personage_voice[character]}
    print(call.message.chat.id)
    requests.post("http://127.0.0.1:5001/change_character", json=request_disp)
    await call.message.edit_text(f"–í—ã –≤—ã–±—Ä–∞–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ {character}")
    await call.message.answer(char_info[char_id])
    if char_id == 'capybara':
        keyboard = types.InlineKeyboardMarkup()
        keyboard.add(types.InlineKeyboardButton(text="–ü–µ—Å–Ω—è 1", callback_data="song1"))
        keyboard.add(types.InlineKeyboardButton(text="–ü–µ—Å–Ω—è 2", callback_data="song2"))
        # keyboard.add(types.InlineKeyboardButton(text="–ì–∏—Ñ–∫–∞", callback_data="gif"))
        await call.message.answer('–Ø –º–æ–≥—É —Å–ø–µ—Ç—å —Ç–µ–±–µ –ø–µ—Å–Ω—é!', reply_markup=keyboard)
    await call.answer()


@dp.callback_query_handler(text_startswith="song")
async def mood_changed(call: types.CallbackQuery):
    song_type = call.data
    await call.message.answer_voice(voice=types.InputFile(f'{song_type}.opus', "r"))
    await call.message.edit_text(f'–î–µ—Ä–∂–∏ –ø–µ—Å–µ–Ω–∫—É!')
    await call.message.answer_animation(animation=types.InputFile('capy.gif'))


@dp.message_handler(commands=['end'])
async def char_change(message: types.Message):
    await message.answer('–í—Å–µ. –≠—Ç–æ –∫–æ–Ω–µ—Ü. –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –Ω–µ –±—É–¥–µ—Ç.')


@dp.message_handler(content_types="text")
async def text_message_handler(message: types.Message):
    if message.is_command():
        return

    request_disp = {"user_id": message.from_user.id, "text": message.text}
    tts_answer = requests.post("http://127.0.0.1:5001/text_query", json=request_disp)
    with tempfile.NamedTemporaryFile(suffix=".wav") as temp_file:
        voice = torch.tensor(tts_answer.json()["audio"]).unsqueeze(0)
        torchaudio.save(temp_file.name, voice, 48000)
        result_file = temp_file.name.replace('wav', 'ogg')
        convert_to_voice_cmd = f"ffmpeg -i {temp_file.name} -c:a libopus {result_file}"
        subprocess.run(f"{convert_to_voice_cmd}", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        await message.answer_voice(voice=types.InputFile(result_file, "r"))
        await message.answer(tts_answer.json()["text_answer"])
        os.remove(result_file)

if __name__ == '__main__':
    executor.start_polling(dp, skip_updates=True)
