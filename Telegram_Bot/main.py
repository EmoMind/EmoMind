from aiogram import Bot, Dispatcher, executor, types
import os
import tempfile
import torchaudio
import requests
import torch
import opuspy
import numpy as np
import subprocess



bot = Bot(token='6294998264:AAGGTSpHfFGabeZGafEB8PxmEMi2uC4t7kU')
dp = Dispatcher(bot)

chars = {"mage":"–û–ª–∏–º–ø–∏—è –∏–∑ –•–æ–≥–≤–∞—Ä—Ç—Å–∞","jedi":"–ô–æ–¥—Ä–∏–∫ –≤–Ω—É–∫ –ô–æ–¥—ã","capybara":"üòé–ö–∞–ø–∏–±–∞—Ä–∞üòé"}

personage_voice = {"–û–ª–∏–º–ø–∏—è –∏–∑ –•–æ–≥–≤–∞—Ä—Ç—Å–∞": "olimpia", "–ô–æ–¥—Ä–∏–∫ –≤–Ω—É–∫ –ô–æ–¥—ã": "yodrick", "üòé–ö–∞–ø–∏–±–∞—Ä–∞üòé": "capybara"}
char_info = {
    'mage': '–ü—Ä–∏–≤–µ—Ç! –Ø —É—á–µ–Ω–∏—Ü–∞ —Ñ–∞–∫—É–ª—å—Ç–µ—Ç–∞ –•–∞—Ñ—Ñ–ª–ø–∞—Ñ—Ñ —à–∫–æ–ª—ã –º–∞–≥–∏–∏ –∏ –≤–æ–ª—à–µ–±—Å—Ç–≤–∞ - –•–æ–≥–≤–∞—Ä—Ç—Å. –ö–∞–∫ –∫–∞–ø–∏—Ç–∞–Ω –∫–æ–º–∞–Ω–¥—ã –ø–æ –∫–≤–∏–¥–¥–∏—á—É —è –∑–¥–µ—Å—å, —á—Ç–æ–±—ã –≤—Å–µ–≥–¥–∞ –≤–¥–æ—Ö–Ω–æ–≤–ª—è—Ç—å —Ç–µ–±—è –Ω–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —Ü–µ–ª–µ–π - –±—É–¥—å —Ç–æ —Å–ø–æ—Ä—Ç –∏–ª–∏ —É—á–µ–±–∞!',
    'jedi': '–ü—Ä–∏–≤–µ—Ç! –Ø - –ô–æ–¥—Ä–∏–∫, —Ç—Ä–æ—é—Ä–æ–¥–Ω—ã–π –≤–Ω—É–∫ —Å–∞–º–æ–≥–æ –º–∞–≥–∏—Å—Ç—Ä–∞ –ô–æ–¥—ã, –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫–æ–º –¥–∂–µ–¥–∞–µ–≤ —è —è–≤–ª—è—é—Å—å. –ì–æ—Ç–æ–≤ —É–∫–∞–∑–∞—Ç—å –ø—É—Ç—å —Ä–µ—à–µ–Ω–∏—è —Ç–≤–æ–∏—Ö –ø—Ä–æ–±–ª–µ–º –ª—é–±—ã—Ö, –¥–∞–∂–µ –µ—Å–ª–∏ –≤ –±–µ–∑–≤—ã—Ö–æ–¥–Ω–æ–º –ø–æ–ª–æ–∂–µ–Ω–∏–∏, —Ç–µ–±–µ –∫–∞–∂–µ—Ç—Å—è, —Ç—ã –æ–∫–∞–∑–∞–ª—Å—è.',
    'capybara': '–§—ã—Ä —Ñ—ã—Ä-—Ñ—ã—Ä —Ñ—ã—Ä-—Ñ—ã—Ä —Ñ—ã—Ä-—Ñ—ã—Ä —Ñ—ã—Ä, —Ñ—ã—Ä. (–ü—Ä–∏–≤–µ—Ç, –º–æ–π –¥–æ—Ä–æ–≥–æ–π –¥—Ä—É–≥! –£–≤–µ—Ä–µ–Ω–∞, —Ç–µ–±–µ —É–∂–µ –∏–∑–≤–µ—Å—Ç–Ω–æ, –∫—Ç–æ —è. –Ø - –≤–µ–ª–∏–∫–∞—è –∫–∞–ø–∏–±–∞—Ä–∞, –∫–æ—Ç–æ—Ä–∞—è –∂–∏–≤–µ—Ç —É–∂–µ –±–æ–ª–µ–µ –º–∏–ª–ª–∏–∞—Ä–¥–∞ –ª–µ—Ç –∏ –≤–∏–¥–µ–ª–∞ –≤–µ–ª–∏–∫–∏–µ —Å–æ–±—ã—Ç–∏—è. –û–±—Ä–∞—â–∞–π—Å—è –∫–æ –º–Ω–µ, –∫–æ–≥–¥–∞ –±—É–¥–µ—Ç –∫–∞–∑–∞—Ç—å—Å—è, —á—Ç–æ –º–∏—Ä –≤–æ–∫—Ä—É–≥ —Å—Ç–∞–ª —Å–ª–æ–∂–Ω—ã–º –∏ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–º. –Ø –≤—Å–µ–≥–¥–∞ –ø–æ–º–æ–≥—É —Ç–µ–±–µ –Ω–∞–π—Ç–∏ –≥–∞—Ä–º–∏–æ–Ω–∏—é –∏ —É—Å–ø–æ–∫–æ–∏—Ç—å—Å—è.)'
}

help_dict = {
     'help_1': '–ü—Ä–∏–≤–µ—Ç, –¥—Ä—É–≥! –Ø —Ä–∞—Å—Å–∫–∞–∂—É —Ç–µ–±–µ, —á—Ç–æ —É–º–µ—é.'+
     '\n–¢—ã –º–æ–∂–µ—à—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –º–Ω–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.'+
     ' \n–Ø –º–æ–≥—É –ø–æ—Å–æ–≤–µ—Ç–æ–≤–∞—Ç—å —Ç–µ–±–µ —Ñ–∏–ª—å–º, –ø–µ—Å–Ω—é, –ø—Ä–æ—Å—Ç–æ –ø–æ–±–æ–ª—Ç–∞—Ç—å —Å —Ç–æ–±–æ–π. –£–¥–∞—á–∏!',
     'help_2': '–î–ª—è –Ω–∞—á–∞–ª–∞ –æ–±—â–µ–Ω–∏—è, –≤—ã–±–µ—Ä–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞. –î–ª—è —ç—Ç–æ–≥–æ –Ω–∞–∂–º–∏ –Ω–∞ –æ–¥–Ω—É –∏–∑ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã—Ö –∫–Ω–æ–ø–æ–∫.'+
     '\n–î–∞–ª–µ–µ, –∑–∞–ø–∏—à–∏ –º–Ω–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.'+
     '\n–ï—Å–ª–∏ —Ç—ã —Ö–æ—á–µ—à—å –ø—Ä–µ–∫—Ä–∞—Ç–∏—Ç—å –æ–±—â–µ–Ω–∏–µ, –Ω–∞–∂–º–∏ –Ω–∞ –∫–Ω–æ–ø–∫—É ¬´/end¬ª –≤ –º–µ–Ω—é. –£–¥–∞—á–∏!'
 }

@dp.message_handler(commands=['start'])
async def onstart(message: types.Message):
    keyboard = types.InlineKeyboardMarkup()
    keyboard.add(types.InlineKeyboardButton(text="–û–ª–∏–º–ø–∏—è –∏–∑ –•–æ–≥–≤–∞—Ä—Ç—Å–∞", callback_data="char_mage"))
    keyboard.add(types.InlineKeyboardButton(text="–ô–æ–¥—Ä–∏–∫ –≤–Ω—É–∫ –ô–æ–¥—ã", callback_data="char_jedi"))
    keyboard.add(types.InlineKeyboardButton(text="üòé–ö–∞–ø–∏–±–∞—Ä–∞üòé", callback_data="char_capybara"))
    await message.answer('–í—ã–±–µ—Ä–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞, —Å –∫–æ—Ç–æ—Ä—ã–º —Ç—ã —Ö–æ—á–µ—à—å –ø–æ–æ–±—â–∞—Ç—å—Å—è', reply_markup=keyboard)
    await message.answer("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º, —á—Ç–æ –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–±–æ—Ç—ã —á–∞—Ç-–±–æ—Ç–∞")


@dp.message_handler(commands=['change_person','cp','cc','change_char','change_character'])
async def char_change(message: types.Message):
    keyboard = types.InlineKeyboardMarkup()
    keyboard.add(types.InlineKeyboardButton(text="–û–ª–∏–º–ø–∏—è –∏–∑ –•–æ–≥–≤–∞—Ä—Ç—Å–∞", callback_data="char_mage"))
    keyboard.add(types.InlineKeyboardButton(text="–ô–æ–¥—Ä–∏–∫ –≤–Ω—É–∫ –ô–æ–¥—ã", callback_data="char_jedi"))
    keyboard.add(types.InlineKeyboardButton(text="üòé–ö–∞–ø–∏–±–∞—Ä–∞üòé", callback_data="char_capybara"))
    await message.answer('–í—ã–±–µ—Ä–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞, —Å –∫–æ—Ç–æ—Ä—ã–º —Ç—ã —Ö–æ—á–µ—à—å –ø–æ–æ–±—â–∞—Ç—å—Å—è', reply_markup=keyboard)

@dp.message_handler(commands=['help'])
async def help(message: types.Message):
    keyboard = types.InlineKeyboardMarkup()
    keyboard.add(types.InlineKeyboardButton(text="–û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è", callback_data="help_1"))
    keyboard.add(types.InlineKeyboardButton(text="–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ", callback_data="help_2"))
    await message.answer('–ü–æ–º–æ—â—å', reply_markup=keyboard)

@dp.message_handler(content_types=[types.ContentType.VOICE])
async def voice_message_handler(message: types.Message):
    with tempfile.NamedTemporaryFile(suffix=".wav") as temp_file:
        file_id = message.voice.file_id
        file = await bot.get_file(file_id)
        file_path = file.file_path
        print(file_path)
        print(temp_file.name)
        await bot.download_file(file_path, temp_file.name)
        audio, s_r = torchaudio.load(temp_file)
    request_disp = {"user_id": message.chat.id, "audio": audio.tolist(), "sample_rate": s_r}
    await message.answer_chat_action(types.ChatActions.RECORD_AUDIO)
    tts_answer = requests.post("http://127.0.0.1:5001/query", json=request_disp)
    with tempfile.NamedTemporaryFile(suffix=".wav") as temp_file:
        if "audio" in tts_answer.json():
            voice = torch.tensor(tts_answer.json()["audio"]).unsqueeze(0)
            torchaudio.save(temp_file.name, voice, 48000)
            result_file = temp_file.name.replace('wav', 'ogg')
            convert_to_voice_cmd = f"ffmpeg -i {temp_file.name} -c:a libopus {result_file}"
            subprocess.run(f"{convert_to_voice_cmd}", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            await message.answer_voice(voice=types.InputFile(result_file, "r"))
        await message.answer(tts_answer.json()["text_answer"])
        os.remove(result_file)

@dp.callback_query_handler(text_startswith="char")
async def char_changed(call: types.CallbackQuery):
    char_id = call.data.split("_")[1]
    character = chars[char_id]
    request_disp = {"user_id": call.message.chat.id, "character": personage_voice[character]}
    print(call.message.chat.id)
    requests.post("http://127.0.0.1:5001/change_character", json=request_disp)
    await call.message.edit_text(f"–í—ã –≤—ã–±—Ä–∞–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞ {character}")
    await call.message.answer_photo(photo=types.InputFile(f"{personage_voice[character]}.png", "r"))
    await call.message.answer_voice(voice=types.InputFile(f'{personage_voice[character]}_welcome.opus', "r"))
    await call.message.answer(char_info[char_id])
    if char_id == 'capybara':
        keyboard = types.InlineKeyboardMarkup()
        keyboard.add(types.InlineKeyboardButton(text="–ü–µ—Å–Ω—è 1", callback_data="song1"))
        keyboard.add(types.InlineKeyboardButton(text="–ü–µ—Å–Ω—è 2", callback_data="song2"))
        # keyboard.add(types.InlineKeyboardButton(text="–ì–∏—Ñ–∫–∞", callback_data="gif"))
        await call.message.answer('–Ø –º–æ–≥—É —Å–ø–µ—Ç—å —Ç–µ–±–µ –ø–µ—Å–Ω—é!', reply_markup=keyboard)
    await call.answer()


@dp.callback_query_handler(text_startswith="song")
async def mood_changed(call: types.CallbackQuery):
    song_type = call.data
    await call.message.answer_voice(voice=types.InputFile(f'{song_type}.opus', "r"))
    await call.message.edit_text(f'–î–µ—Ä–∂–∏ –ø–µ—Å–µ–Ω–∫—É!')
    await call.message.answer_animation(animation=types.InputFile('capy.gif'))


@dp.callback_query_handler(text_startswith="help")
async def mood_changed(call: types.CallbackQuery):
     help_type = call.data
     await call.message.edit_text(f'{help_dict[help_type]}')


@dp.message_handler(commands=['end'])
async def char_change(message: types.Message):
    await message.answer('–í—Å–µ. –≠—Ç–æ –∫–æ–Ω–µ—Ü. –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è –Ω–µ –±—É–¥–µ—Ç.')


@dp.message_handler(content_types="text")
async def text_message_handler(message: types.Message):
    await message.answer("–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø–æ–∫–∞ —è —É–º–µ—é –æ—Ç–≤–µ—á–∞—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è")
#    if message.is_command():
#        return
#
#    request_disp = {"user_id": message.from_user.id, "text": message.text}
#    await message.answer_chat_action(types.ChatActions.RECORD_AUDIO)
#    tts_answer = requests.post("http://127.0.0.1:5001/text_query", json=request_disp)
#    with tempfile.NamedTemporaryFile(suffix=".wav") as temp_file:
#        if "audio" in tts_answer.json():
#            voice = torch.tensor(tts_answer.json()["audio"]).unsqueeze(0)
#            torchaudio.save(temp_file.name, voice, 48000)
#            result_file = temp_file.name.replace('wav', 'ogg')
#            convert_to_voice_cmd = f"ffmpeg -i {temp_file.name} -c:a libopus {result_file}"
#            subprocess.run(f"{convert_to_voice_cmd}", shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
#            await message.answer_voice(voice=types.InputFile(result_file, "r"))
#        await message.answer(tts_answer.json()["text_answer"])
#        os.remove(result_file)

if __name__ == '__main__':
    executor.start_polling(dp, skip_updates=True)
